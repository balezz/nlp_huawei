{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zk4lzm5ANkMc"
   },
   "source": [
    "### Assignment 2: Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pb5x0mRuONbf",
    "outputId": "f6f5240b-67d1-4e2a-a461-4fa871f24774"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile\t\t       image.tar\r\n",
      "README.MD\t\t       jigsaw-incredibly-simple-naive-bayes-0-768.ipynb\r\n",
      "ReplaceDataset.ipynb\t       model.py\r\n",
      "__pycache__\t\t       project\r\n",
      "baseline_model.ckpt\t       requirements.txt\r\n",
      "baseline_solution.ipynb        run.sh\r\n",
      "classify_text_with_bert.ipynb  trainer.py\r\n",
      "data\t\t\t       utils.py\r\n",
      "data_preprocessing.py\t       venv\r\n",
      "gensim-data\r\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "P9KR3pSYNkMg",
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "import os\n",
    "import csv\n",
    "from random import seed\n",
    "from pathlib import Path\n",
    "from itertools import chain\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from IPython.display import HTML, display\n",
    "import gensim.downloader as api\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pack_sequence\n",
    "from data_preprocessing import read_data,read_test, Tokenizer, TextDataset,\\\n",
    "    Vocab,train_test_split\n",
    "from utils import show_example\n",
    "from model import prepare_emb_matrix, RecurrentClassifier\n",
    "from trainer import Trainer\n",
    "# from google.colab import files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbqBRMI2NkMi"
   },
   "source": [
    "Toxicity, such as insults, threats and hate speech, in online conversations is a real threat to productive sharing of opinons. To mitigate this problem automatic comment filtering system may be applied.\n",
    "In this assignment you are provided with data, collected by [Jigsaw](https://jigsaw.google.com/\n",
    ") company from Wikipediaâ€™s talk page edits. Each comment was labeled with toxicity rating from 0 to 5. Here are some examples of the least toxic comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "KyQPJDJRNkMj",
    "outputId": "e1fc836f-ef9f-48f0-cb32-4ced14b6c41d",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <!DOCTYPE html>\n",
       "    <html>\n",
       "    <table>\n",
       "    <tr> <th>Toxicity</th> <th>Comment</th>\n",
       "    \n",
       "    <TR>\n",
       "       <TD class=\"c1\" style=\"text-align:center; font-size:large\" title=\"Toxicity Rating: 0\">&#128519;</TD>\n",
       "       <TD class=\"c2\" style=\"font-size:large\"> legal action  wikipedia has a policy  wp nlt and i agree with it completely  however  they do add the following if you must take legal action  we cannot prevent you from doing so  however  it is required that you do not edit wikipedia until the legal matter has been resolved to ensure that all legal processes happen via proper legal channels  you should instead contact the person or people involv...</TD>\n",
       "    </TR>\n",
       "    \n",
       "    <TR>\n",
       "       <TD class=\"c1\" style=\"text-align:center; font-size:large\" title=\"Toxicity Rating: 1\">&#128528;</TD>\n",
       "       <TD class=\"c2\" style=\"font-size:large\">don t be a douche towards me </TD>\n",
       "    </TR>\n",
       "    \n",
       "    <TR>\n",
       "       <TD class=\"c1\" style=\"text-align:center; font-size:large\" title=\"Toxicity Rating: 2\">&#128551;</TD>\n",
       "       <TD class=\"c2\" style=\"font-size:large\">  ok  now you re pissing me off  stop accusing me of things that aren t real  what  in the his noddlinesses name are you talking about  i repeat  in vulgar and block worthy language  because your irrationality is making you impossible i don t give a  shit  about the reference to affirmative action  i ve said it three times  repeated it in the post you are refering to  and still you went on to make...</TD>\n",
       "    </TR>\n",
       "    \n",
       "    </table>\n",
       "    </html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = read_data()\n",
    "seed(4)\n",
    "\n",
    "# change this at your own risk \n",
    "ratings_to_show = (0, 1, 2)\n",
    "display(HTML(show_example(data, ratings=ratings_to_show)))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g072aRdDNkMk"
   },
   "source": [
    "The task is to build a classifier system. Let's create a baseline recurrent model. We'll start with building a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "L5BkEZOdNkMk",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Press shift-tab to check docstrings\n",
    "tok = Tokenizer()\n",
    "tok_texts = [tok.tokenize(t) for t in chain(*data.values())]\n",
    "vocab = Vocab(tok_texts, max_vocab_size=30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3OO4t1KxNkMl"
   },
   "source": [
    "Then data is splitted into train and validation parts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0vNHxoveNkMm",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_texts, train_labels, val_texts, val_labels = train_test_split(data)\n",
    "train_dataset = TextDataset([tok.tokenize(t) for t in train_texts], train_labels, vocab)\n",
    "val_dataset = TextDataset([tok.tokenize(t) for t in val_texts], val_labels, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UG5nWPI6NkMn"
   },
   "source": [
    "Then pretrained embeddings are obtained with Gensim - it'll automatically download them for you. [Here](https://github.com/RaRe-Technologies/gensim-data#models\n",
    ") you can see other pretrained embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FcOgEhneNkMn",
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 128.1/128.1MB downloaded\n"
     ]
    }
   ],
   "source": [
    "# store embeddings in current directory\n",
    "os.environ[\"GENSIM_DATA_DIR\"] = str(Path.cwd())\n",
    "# will download embeddings or load them from disk\n",
    "gensim_model = api.load(\"glove-wiki-gigaword-100\")\n",
    "emb_matrix = prepare_emb_matrix(gensim_model, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0GNVk72HNkMo"
   },
   "source": [
    "Now let's define hyperparameters for our baseline model. It'll be a 2-layered unidiractional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HAT3dKn3NkMo",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"freeze\": True,\n",
    "    \"cell_type\": \"LSTM\",\n",
    "    \"cell_dropout\": 0.3,\n",
    "    \"num_layers\": 2,\n",
    "    \"hidden_size\": 128,\n",
    "    \"out_activation\": \"relu\",\n",
    "    \"bidirectional\": True,\n",
    "    \"out_dropout\": 0.2,\n",
    "    \"out_sizes\": [200],\n",
    "}\n",
    "\n",
    "trainer_config = {\n",
    "    \"lr\": 3e-4,\n",
    "    \"n_epochs\": 10,\n",
    "    \"weight_decay\": 1e-6,\n",
    "    \"batch_size\": 128,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "}\n",
    "clf_model = RecurrentClassifier(config, vocab, emb_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_l08MW7oNkMp",
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, \n",
    "                              batch_size=trainer_config[\"batch_size\"],\n",
    "                              shuffle=True,\n",
    "                              num_workers=2,\n",
    "                              collate_fn=train_dataset.collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, \n",
    "                            batch_size=trainer_config[\"batch_size\"],\n",
    "                            shuffle=False,\n",
    "                            num_workers=2,\n",
    "                            collate_fn=val_dataset.collate_fn)\n",
    "t = Trainer(trainer_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WNsmVOu3cpdV"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72078b70d2f1441e834435fdcc0c1028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=231.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t.fit(clf_model, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVQOjtYoNkMq",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's save model, load it from checkpoint and check on some commments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360
    },
    "id": "KyhtW6oGNkMq",
    "outputId": "36d344e8-aa6c-49ea-d45e-c3ba55763cb9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t.save(\"baseline_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "id": "C7FeOu3TNkMq",
    "outputId": "2da0d7f2-8185-4c8d-dc56-5ca57cd6bd67",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t = Trainer.load(\"baseline_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QmrTOQh0cu1h"
   },
   "outputs": [],
   "source": [
    "def predict_toxicity(model, comment):\n",
    "    tok_text = tok.tokenize(comment)\n",
    "    indexed_text = torch.tensor(vocab.vectorize(tok_text)).to(t.device)\n",
    "    rating = model(pack_sequence([indexed_text])).argmax().item()\n",
    "    print(f\"Toxicity rating for \\\"{comment}\\\" is: {rating}\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "bvS3ByPiNkMr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxicity rating for \"Please sir do not delete my edits\" is: 0\n",
      "Toxicity rating for \"They are nazi pal, forget it\" is: 0\n",
      "Toxicity rating for \"You suck\" is: 0\n"
     ]
    }
   ],
   "source": [
    "predict_toxicity(t.model, \"Please sir do not delete my edits\")\n",
    "predict_toxicity(t.model, \"They are nazi pal, forget it\")\n",
    "predict_toxicity(t.model, \"You suck\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "msNQtvffNkMr",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now let's prepare a submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "nua2JHuCNkMr"
   },
   "outputs": [],
   "source": [
    "test_uuids, test_texts = read_test(\"data/test.csv\")\n",
    "test_dataloader = DataLoader( TextDataset([tok.tokenize(t) for t in test_texts], [-1] * len(test_texts), vocab), \n",
    "                            batch_size=trainer_config[\"batch_size\"],\n",
    "                            shuffle=False,\n",
    "                            num_workers=2,\n",
    "                            collate_fn=val_dataset.collate_fn)\n",
    "\n",
    "predictions = t.predict(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "y-dfGcATNkMs",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_test_predictions(test_predictions, path):\n",
    "    assert len(test_predictions) == len(test_texts)\n",
    "    with open(path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile, delimiter=',')\n",
    "        writer.writerow([\"uuid\",\"comment_text\",\"toxicity\"])\n",
    "        for uuid, text, pred in zip(test_uuids, test_texts, test_predictions):\n",
    "            writer.writerow([uuid, text, pred])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "IeDNBx61fkkm"
   },
   "outputs": [],
   "source": [
    "save_test_predictions(predictions, \"./best_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9A4bAbcNkMs"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nUxXjuoNkMs"
   },
   "source": [
    "Note that generally not all errors are equal: for example, predicting score 0 while the target is 5 is seemingly worse than predicting 3 instead of 4. That's why your model will be evaluated by [MSE](https://en.wikipedia.org/wiki/Mean_squared_error) loss used for regression tasks. Also note that your model is not required to predict integers, scores like 0.31, 2.718 etc. are fine too. Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgXy-DpmNkMt"
   },
   "source": [
    "### Optional part: automatic hyperparameter tuning with Optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cn9q0n_tNkMt"
   },
   "source": [
    "Optuna is a framework which lets you easily tweak hypermarameters of your model. In this part we'll use it to improve quality on validation data - we'll select model with best accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "UwdYmFQDNkMt",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from optuna import create_study\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "BEST_ACC = 0.0\n",
    "\n",
    "def objective(trial):\n",
    "    global BEST_ACC\n",
    "    \n",
    "    n_hidden_layers = trial.suggest_int(\"n_hidden_layers\", 0, 3)\n",
    "    hidden_layer_size = trial.suggest_int(\"hidden_layer_size\", 10, 1000)\n",
    "    \n",
    "    config = {\n",
    "        \"freeze\": True,\n",
    "        \"cell_type\": trial.suggest_categorical(\"cell_type\", [\"RNN\", \"LSTM\", \"GRU\"]),\n",
    "        \"cell_dropout\": trial.suggest_loguniform(\"cell_dropout\", 1e-9, 0.9),\n",
    "        \"num_layers\": trial.suggest_int(\"num_layers\", 1, 3),\n",
    "        \"hidden_size\": trial.suggest_int(\"hidden_size\", 10, 1000),\n",
    "        \"out_activation\": trial.suggest_categorical(\"out_activation\", \n",
    "                                                    [\"sigmoid\", \"tanh\", \"relu\", \"elu\"]),\n",
    "        \"bidirectional\": trial.suggest_categorical(\"bidirectional\", [True, False]),\n",
    "        \"out_dropout\": trial.suggest_loguniform(\"out_dropout\", 1e-9, 0.9),\n",
    "        \"out_sizes\": [hidden_layer_size] * n_hidden_layers,\n",
    "    }\n",
    "\n",
    "    trainer_config = {\n",
    "        \"lr\": trial.suggest_loguniform(\"lr\", 1e-5, 1e-3),\n",
    "        \"n_epochs\": 10,\n",
    "        \"weight_decay\": trial.suggest_loguniform(\"weight_decay\", 1e-9, 1e-1),\n",
    "        \"batch_size\": 128,\n",
    "        \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "        \"verbose\": False,\n",
    "    }\n",
    "    \n",
    "    pprint({**config, **trainer_config})\n",
    "        \n",
    "    clf_model = RecurrentClassifier(config, vocab, emb_matrix)\n",
    "    t = Trainer(trainer_config)\n",
    "    t.fit(clf_model, train_dataloader, val_dataloader)\n",
    "    val_acc =  t.history[\"val_acc\"][-1]\n",
    "    if val_acc > BEST_ACC:\n",
    "        BEST_ACC = val_acc\n",
    "        t.save(\"optuna_model.ckpt\")\n",
    "    return val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzGVhYlkNkMu",
    "outputId": "389c6874-96c1-479e-e2dd-7a97ab3a7aa4",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-19 23:26:02,500]\u001b[0m A new study created in memory with name: no-name-dc881e23-bbac-4108-b200-840bf137bf79\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'bidirectional': True,\n",
      " 'cell_dropout': 1.363200811191809e-09,\n",
      " 'cell_type': 'LSTM',\n",
      " 'device': 'cuda',\n",
      " 'freeze': True,\n",
      " 'hidden_size': 945,\n",
      " 'lr': 0.0002709704518031192,\n",
      " 'n_epochs': 10,\n",
      " 'num_layers': 1,\n",
      " 'out_activation': 'sigmoid',\n",
      " 'out_dropout': 0.0001898671521172181,\n",
      " 'out_sizes': [],\n",
      " 'verbose': False,\n",
      " 'weight_decay': 2.659101704286755e-09}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=1.363200811191809e-09 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "\u001b[32m[I 2022-03-20 00:09:08,492]\u001b[0m Trial 0 finished with value: 0.6824389100074768 and parameters: {'n_hidden_layers': 0, 'hidden_layer_size': 311, 'cell_type': 'LSTM', 'cell_dropout': 1.363200811191809e-09, 'num_layers': 1, 'hidden_size': 945, 'out_activation': 'sigmoid', 'bidirectional': True, 'out_dropout': 0.0001898671521172181, 'lr': 0.0002709704518031192, 'weight_decay': 2.659101704286755e-09}. Best is trial 0 with value: 0.6824389100074768.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'bidirectional': True,\n",
      " 'cell_dropout': 1.737630799239919e-07,\n",
      " 'cell_type': 'LSTM',\n",
      " 'device': 'cuda',\n",
      " 'freeze': True,\n",
      " 'hidden_size': 403,\n",
      " 'lr': 0.00012744432100486,\n",
      " 'n_epochs': 10,\n",
      " 'num_layers': 1,\n",
      " 'out_activation': 'elu',\n",
      " 'out_dropout': 1.4000305680633312e-09,\n",
      " 'out_sizes': [],\n",
      " 'verbose': False,\n",
      " 'weight_decay': 0.09296283365311885}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:65: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=1.737630799239919e-07 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n",
      "\u001b[32m[I 2022-03-20 00:21:12,200]\u001b[0m Trial 1 finished with value: 0.5399115085601807 and parameters: {'n_hidden_layers': 0, 'hidden_layer_size': 30, 'cell_type': 'LSTM', 'cell_dropout': 1.737630799239919e-07, 'num_layers': 1, 'hidden_size': 403, 'out_activation': 'elu', 'bidirectional': True, 'out_dropout': 1.4000305680633312e-09, 'lr': 0.00012744432100486, 'weight_decay': 0.09296283365311885}. Best is trial 0 with value: 0.6824389100074768.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'bidirectional': True,\n",
      " 'cell_dropout': 7.095218214633027e-05,\n",
      " 'cell_type': 'LSTM',\n",
      " 'device': 'cuda',\n",
      " 'freeze': True,\n",
      " 'hidden_size': 500,\n",
      " 'lr': 7.329019208213213e-05,\n",
      " 'n_epochs': 10,\n",
      " 'num_layers': 2,\n",
      " 'out_activation': 'elu',\n",
      " 'out_dropout': 0.0001300590300630621,\n",
      " 'out_sizes': [],\n",
      " 'verbose': False,\n",
      " 'weight_decay': 3.411667708190876e-06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-20 01:10:00,920]\u001b[0m Trial 2 finished with value: 0.666089653968811 and parameters: {'n_hidden_layers': 0, 'hidden_layer_size': 813, 'cell_type': 'LSTM', 'cell_dropout': 7.095218214633027e-05, 'num_layers': 2, 'hidden_size': 500, 'out_activation': 'elu', 'bidirectional': True, 'out_dropout': 0.0001300590300630621, 'lr': 7.329019208213213e-05, 'weight_decay': 3.411667708190876e-06}. Best is trial 0 with value: 0.6824389100074768.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 128,\n",
      " 'bidirectional': True,\n",
      " 'cell_dropout': 0.0002312210196735422,\n",
      " 'cell_type': 'LSTM',\n",
      " 'device': 'cuda',\n",
      " 'freeze': True,\n",
      " 'hidden_size': 640,\n",
      " 'lr': 3.9504684560636326e-05,\n",
      " 'n_epochs': 10,\n",
      " 'num_layers': 2,\n",
      " 'out_activation': 'relu',\n",
      " 'out_dropout': 8.066887477400993e-06,\n",
      " 'out_sizes': [297, 297],\n",
      " 'verbose': False,\n",
      " 'weight_decay': 1.6439079357128654e-06}\n"
     ]
    }
   ],
   "source": [
    "study = create_study(direction=\"maximize\")\n",
    "# you can set more trials\n",
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_YjYueWNkMu"
   },
   "source": [
    "### Final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ljfpeIcFbRgM"
   },
   "outputs": [],
   "source": [
    "t = Trainer.load(\"optuna_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XDqn8ilmNkMu",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "save_test_predictions(t.predict(test_dataloader), \"./best_results_hparam_search.csv\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "baseline_solution.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
